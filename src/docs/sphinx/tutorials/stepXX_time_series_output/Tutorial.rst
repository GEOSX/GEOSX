.. _TutorialTimeSeriesOutput:

####################################################################
Tutorial XX: Time series output
####################################################################

**Context**

In this brief tutorial, we will focus on how to use GEOSX to collect and
store time series data produced during simulations.
This is commonly used to extract well injection or production rates or pressures as a function of time,
or to collect cell-based property values in a specific part of the reservoir as they evolve over the simulation runtime. We call this type of information **Time History** data.


Before starting, it is important to remember that GEOSX is designed for distributed computing.
While the task of reporting and saving runtime data is simple in serial simulation tools,
gathering runtime information efficiently when it is located in multiple locations requires more advanced approaches.


Fortunately in GEOSX, specific *packing* mechanisms have been implemented.
These packing mechanisms offer fine-grained controls over the type of data to collect,
the frequency of data collection, and the frequency of transfer to file
of these corrections.


**Objectives**

At the end of this tutorial you will know how to export time series data from GEOSX and learn:

  - how to use **PackCollection** task objects to indicate *which information* to collect,
  - how to use **TimeHistory** output objects to indicate *where to store* time series data,
  - how to use **Events** to control *when to collect* information and *when to save* the collected information,
  - how to look into the output files generated by GEOSX with the collected information,
  - examples of how to post-process these output files with standard Python plotting methods (using MatPlotLib_, here).

**Input file**

This tutorial uses the same data as in :ref:`multiphase flow with well <TutorialDeadOilBottomLayersSPE10>` and the XML file describing this case is located at

.. code-block:: console

  src/coreComponents/physicsSolvers/fluidFlow/benchmarks/SPE10/dead_oil_spe10_layers_83_84_85.xml


For information about the physical problem solved in the case, please refer to the :ref:`tutorial <TutorialDeadOilBottomLayersSPE10>`.

Here, the focus is on exporting time series data and will not cover
other aspects of this simulation run.


------------------------------------------------------------------------
Outputs, Tasks, and Events to trigger them
------------------------------------------------------------------------


Here is how to create and export time series data in GEOSX:

#. First, data collection: we need to set up an XML node to specify which data to save. This act of collecting data is a ``Task`` called a ``PackCollection``. It packs together values of a particular property *field* on a particular support *object* (say, the pressure at a particular well perforation). The number of ``PackCollection`` nodes is not limited.
#. Second, data output: we need to designate a ``TimeHistory`` node in the ``Outputs`` section. This ``TimeHistory`` node ties together a container with one or multiple ``PackCollection`` objects. At the moment, containers are HDF5_ files written to disk.
#. Then, two events: one event is needed to trigger the data collection, one event is needed to trigger the output. These two events specify the time or frequency to collect the ``PackCollection`` values, and the time/frequency to output to file. Both timings need not be identical to better control memory usage and motions.

Specifying these XML nodes (one for the task, one for the output, and two for the events) creates
a complete data output pipeline.

There is no limit to the number of time history output pipelines in GEOSX and this creates a lot of flexibility to output various data types at various runtimes.

In this documentation, we show an overview on an example of the XML tags.
We start our description with the output file and work our way up to the data source.
This helps with clarity and intent.
While the order in which the nodes are specified in the XML input file is not important,
it is important that each node connects to the next node
by specifying names exactly like defined (in the user-defined ``name`` attribute of each node).


Outputs and TimeHistory: specifying which data goes in which file
------------------------------------------------------------------------------

To export time series to a file, we add a ``<TimeHistory>`` XML node in the ``<Outputs>`` section of the XML file.

This ``TimeHistory`` node contains at minimum the name of a data source,
the name of an output file, and of course, its own object name.
No extension is needed to the filename (''.hdf5'' will be added by default).

.. literalinclude:: ../../../../coreComponents/physicsSolvers/fluidFlow/benchmarks/SPE10/dead_oil_spe10_layers_83_84_85.xml
  :language: xml
  :start-after: <!-- SPHINX_TUT_DEAD_OIL_BOTTOM_SPE10_OUTPUT -->
  :end-before: <!-- SPHINX_TUT_DEAD_OIL_BOTTOM_SPE10_OUTPUT_END -->

A complete decription of the <``TimeHistory``> node is provided in the :ref:`output section<Outputs>`.


Tasks and PackCollections: specifying which data to export
------------------------------------------------------------------------------

Time history collection events target a specific **Task**. Here, to produce time series output, the task consists in assembling (packing) a snapshot in time of a collection of values mounted on the specific field of a specific object, identified by their name and path respectively. The object could, for instance, be a well in the object path and the field could be perforation pressure value. We use the ``PackCollection`` node. Each pack must have a user-defined ``name``, and it must point to an ``objectPath`` with a ``fieldName``.

.. literalinclude:: ../../../../coreComponents/physicsSolvers/fluidFlow/benchmarks/SPE10/dead_oil_spe10_layers_83_84_85.xml
  :language: xml
  :start-after: <!-- SPHINX_TUT_DEAD_OIL_BOTTOM_SPE10_TASKS -->
  :end-before: <!-- SPHINX_TUT_DEAD_OIL_BOTTOM_SPE10_TASKS_END -->


For more on this topic, see :ref:`TasksManager`.

Events:
------------------------------------------------------------------------------

:ref:`Events<EventManager>` are used to trigger both the collection actions and the output actions at set simulation times or frequencies.

  #. To time the collection of data: we use the ``target`` attribute on a **task** node by using its path to the user-defined name (``/Tasks/myCollectionName``)
  #. To time the output of data: we use the ``target`` attribute on an **output** node with its path to the user-defined name (``/Outputs/myTimeHistoryName``).


More information about events can be found at :ref:`EventManager`.

.. literalinclude:: ../../../../coreComponents/physicsSolvers/fluidFlow/benchmarks/SPE10/dead_oil_spe10_layers_83_84_85.xml
  :language: xml
  :start-after: <!-- SPHINX_TUT_DEAD_OIL_BOTTOM_SPE10_EVENTS -->
  :end-before: <!-- SPHINX_TUT_DEAD_OIL_BOTTOM_SPE10_EVENTS_END -->



------------------------------------------------------------------------
HDFView: inspecting GEOSX time series output files (HDF5)
------------------------------------------------------------------------

Time series exported by GEOSX are stored as HDF5_ files.
The HDF5 format is built for fast I/O processing and storage of heterogeneous data types.
Because of its compression, a reader is necessary to visually inspect the content of an HDF5 formatted file (simply opening an HDF5 file in a text editor will not make the content readable by humans).
HDFview_ is a compact tool developed by the HDF group as a companion to the HDF5 standard. With HDFView, the contents of HDF5 files are directly accessible.


Most of the time though, reading data values from files is not necessary and can be done by more interactive means: Python modules can, for instance, read and interpret HDF5 files. This offers full flexibility to process time series produced by GEOSX in a systematic, algorithmic, manner.


------------------------------------------------------------------------
Exploiting (plotting, analyzing) the output files
------------------------------------------------------------------------

An example MatPlotLib_ plotting script of HDF5 files is shown at the bottom of :ref:`TutorialDeadOilBottomLayersSPE10`.
To read HDF5 files, the  Python module ``h5py`` is used here, in conjunction with Numpy.

.. code-block:: python


   import h5py
   import numpy as np

   # File path
   hdf5FilePath = "./Path/to/GeosxOutputFile.hdf5"

   # Read HDF5
   hf = h5py.File(hdf5FilePath, 'r')
   time = hf.get('Time')  # Getter
   time = np.array(time)  # Convert to Numpy (if desired)
   massRate = hf.get('wellElementMixtureConnectionRate')
   massRate = np.array(massRate)


This connection between GEOSX, HDF5, and Python modules offers full flexibility to process the time series output of GEOSX.

------------------------------------
To go further
------------------------------------

**Feedback on this tutorial**

For any feedback on this brief tutorial, please submit
a `GitHub issue on the project's GitHub page <https://github.com/GEOSX/GEOSX/issues>`_.

**Next tutorial**

In :ref:`TutorialDeadOilEgg`, we learn how to put this to use on a test case based on the Egg model.

**For more details**

  - A complete description of outputs is found here: :ref:`Outputs`.
  - Tasks and PackCollections are described here :ref:`TasksManager`.
  - A complete description of events is located at :ref:`EventManager`.


.. _SILO: https://wci.llnl.gov/simulation/computer-codes/silo
.. _VTK: https://vtk.org/wp-content/uploads/2015/04/file-formats.pdf
.. _HDF5: https://portal.hdfgroup.org/display/HDF5/HDF5
.. _HDFview: https://www.hdfgroup.org/downloads/hdfview/
.. _VisIT: https://wci.llnl.gov/simulation/computer-codes/visit/downloads
.. _Paraview: https://www.paraview.org/
.. _MatPlotLib: https://matplotlib.org/
